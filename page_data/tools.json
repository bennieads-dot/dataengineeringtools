[
  {
    "pageUrl": "azure",
    "name": "Microsoft Azure",
    "category": "Cloud Platform",
    "description": "Microsoft Azure is a cloud computing platform offering a wide range of services including virtual computing, storage, analytics, and networking.",
    "logo": "https://brandlogos.net/wp-content/uploads/2022/07/microsoft_azure-logo_brandlogos.net_mlyt6-512x512.png",
    "getStarted": "https://learn.microsoft.com/en-us/azure/azure-portal/azure-portal-quickstart-center",
    "EITMLI18": "Azure is a comprehensive cloud platform that provides a vast array of services for building, deploying, and managing applications and services through Microsoft-managed data centers.",
    "url": "https://azure.microsoft.com",
    "useCases": "- Cloud computing\n- Web hosting\n- Data analytics",
    "isOpenSource": false
  },
  {
    "pageUrl": "gcp",
    "name": "Google Cloud Platform (GCP)",
    "category": "Cloud Platform",
    "description": "Google Cloud Platform is a set of cloud computing services that Google offers, including virtual machines, storage, networking, and more",
    "logo": "https://brandlogos.net/wp-content/uploads/2022/07/google_cloud-logo_brandlogos.net_qxnsy-512x512.png",
    "getStarted": "https://cloud.google.com/docs/get-started",
    "EITMLI18": "GCP provides a set of cloud computing services that run on Google's infrastructure, allowing you to build, test, and deploy applications on a highly scalable and reliable platform.",
    "url": "https://cloud.google.com",
    "useCases": "- Cloud storage\n- Machine learning\n- Big data processing",
    "isOpenSource": false
  },
  {
    "pageUrl": "aws",
    "name": "Amazon Web Services (AWS)",
    "category": "Cloud Platform",
    "description": "AWS offers a broad set of global cloud-based products including compute, storage, databases, analytics, networking, mobile, developer tools, and IoT.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/aws.png",
    "getStarted": "https://aws.amazon.com/getting-started/",
    "EITMLI18": "AWS provides a vast array of cloud services that allow you to build sophisticated, scalable applications with increased flexibility, security and reliability.",
    "url": "https://aws.amazon.com",
    "useCases": "- Cloud computing\n- Database management\n- Content delivery",
    "isOpenSource": false
  },
  {
    "pageUrl": "lambda",
    "name": "AWS Lambda",
    "category": "Compute",
    "description": "AWS Lambda lets you run code without provisioning or managing servers, executing code only when needed and scaling automatically.",
    "logo": "https://icon.icepanel.io/AWS/svg/Compute/Lambda.svg",
    "getStarted": "https://docs.aws.amazon.com/lambda/latest/dg/getting-started.html",
    "EITMLI18": "Lambda is like a magic function in the cloud that runs your code automatically in response to events, without you having to worry about servers or scaling.",
    "url": "https://aws.amazon.com/lambda",
    "useCases": "- Serverless computing\n- Event-driven applications\n- Microservices",
    "isOpenSource": false
  },
  {
    "pageUrl": "azure-functions",
    "name": "Azure Functions",
    "category": "Compute",
    "description": "Azure Functions is a serverless solution that allows you to write less code, maintain less infrastructure, and save on costs.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/functions.svg",
    "getStarted": "https://docs.microsoft.com/en-us/azure/azure-functions/functions-overview",
    "EITMLI18": "Azure Functions is like having small pieces of code that wake up and do their job whenever they're needed, without you having to manage any servers.",
    "url": "https://azure.microsoft.com/en-us/products/functions",
    "useCases": "- Serverless computing\n- Event processing\n- Background tasks",
    "isOpenSource": false
  },
  {
    "pageUrl": "docker",
    "name": "Docker",
    "category": "Containerization",
    "description": "Docker is a platform for developing, shipping, and running applications in containers, ensuring consistency across different environments.",
    "logo": "https://cdn4.iconfinder.com/data/icons/logos-and-brands/512/97_Docker_logo_logos-512.png",
    "getStarted": "https://docs.docker.com/get-started/",
    "EITMLI18": "Docker allows you to package your application and all its dependencies into a standardized unit called a container, making it easy to deploy and run your software on any system.",
    "url": "https://www.docker.com",
    "useCases": "- Application containerization\n- Microservices\n- DevOps",
    "isOpenSource": true
  },
  {
    "pageUrl": "segment",
    "name": "Segment",
    "category": "Customer Data Platform",
    "description": "Segment is a customer data platform that helps you collect, clean, and control your customer data.",
    "logo": "https://media.graphassets.com/ZYqNOo1hTVy0djlkIgHA",
    "getStarted": "https://segment.com/docs/",
    "EITMLI18": "Segment is like a central hub for all your customer data, helping you collect information from various sources and send it to the tools you use for marketing, analytics, and more.",
    "url": "https://segment.com",
    "useCases": "- Customer data collection\n- Data integration\n- Marketing analytics",
    "isOpenSource": false
  },
  {
    "pageUrl": "iceberg",
    "name": "Apache Iceberg",
    "category": "Data Format",
    "description": "Apache Iceberg is a table format for large analytic datasets that provides high performance and reliability for data lakes.",
    "logo": "https://py.iceberg.apache.org/assets/images/iceberg-logo-icon.png",
    "getStarted": "https://iceberg.apache.org/spark-quickstart/",
    "EITMLI18": "Iceberg is a modern table format for data lakes that allows you to manage large analytical datasets with improved performance, reliability, and features like schema evolution and time travel.",
    "url": "https://iceberg.apache.org",
    "useCases": "- Data lake management\n- Analytics\n- Large-scale data processing",
    "isOpenSource": true
  },
  {
    "pageUrl": "json",
    "name": "JSON",
    "category": "Data Format",
    "description": "JSON (JavaScript Object Notation) is a lightweight data-interchange format that is easy for humans to read and write and easy for machines to parse and generate.",
    "logo": "https://www.json.org/img/json160.gif",
    "getStarted": "https://www.w3schools.com/js/js_json_intro.asp",
    "EITMLI18": "JSON is like a universal language for data, providing a simple way to store and exchange information that both humans and computers can understand easily.",
    "url": "https://www.json.org",
    "useCases": "- Data interchange\n- Configuration files\n- API responses",
    "isOpenSource": true
  },
  {
    "pageUrl": "xml",
    "name": "XML",
    "category": "Data Format",
    "description": "XML (eXtensible Markup Language) is a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable.",
    "logo": "https://www.svgrepo.com/show/31053/xml.svg",
    "getStarted": "https://www.w3schools.com/xml/default.asp",
    "EITMLI18": "XML is like a versatile container for data, allowing you to structure information in a way that's meaningful for both humans and computers, often used for config files and data exchange.",
    "url": "https://www.w3schools.com/xml/xml_whatis.asp",
    "useCases": "- Data interchange\n- Configuration files\n- Web services",
    "isOpenSource": true
  },
  {
    "pageUrl": "csv",
    "name": "CSV",
    "category": "Data Format",
    "description": "CSV (Comma-Separated Values) is a simple file format used to store tabular data, such as a spreadsheet or database.",
    "logo": "https://www.svgrepo.com/show/375309/csv-document.svg",
    "getStarted": "https://www.geeksforgeeks.org/working-csv-files-python/",
    "EITMLI18": "CSV is like a simple table format for data, where each line is a row and commas separate the columns, making it easy to exchange data between different programs.",
    "url": "https://en.wikipedia.org/wiki/Comma-separated_values",
    "useCases": "- Data storage\n- Data exchange\n- Spreadsheet compatibility",
    "isOpenSource": true
  },
  {
    "pageUrl": "parquet",
    "name": "Parquet",
    "category": "Data Format",
    "description": "Apache Parquet is a columnar storage file format designed for efficient data storage and retrieval.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/parquet.png",
    "getStarted": "https://arrow.apache.org/docs/python/parquet.html",
    "EITMLI18": "Parquet is like a super-efficient filing cabinet for your data, storing it in a way that makes it quick to read and analyze, especially for large datasets.",
    "url": "https://parquet.apache.org",
    "useCases": "- Big data storage\n- Analytics\n- Data warehousing",
    "isOpenSource": true
  },
  {
    "pageUrl": "avro",
    "name": "Avro",
    "category": "Data Format",
    "description": "Apache Avro is a data serialization system that provides rich data structures and a compact, fast, binary data format.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/avro.png",
    "getStarted": "https://avro.apache.org/docs/1.12.0/getting-started-python/",
    "EITMLI18": "Avro is like a universal language for data, allowing you to define complex data structures and serialize them in a compact format that's easy for computers to process quickly.",
    "url": "https://avro.apache.org",
    "useCases": "- Data serialization\n- Big data processing\n- Schema evolution",
    "isOpenSource": true
  },
  {
    "pageUrl": "orc",
    "name": "ORC",
    "category": "Data Format",
    "description": "Apache ORC (Optimized Row Columnar) is a highly efficient columnar storage file format for Hadoop workloads.",
    "logo": "https://cdn.icon-icons.com/icons2/2699/PNG/512/apache_orc_logo_icon_167862.png",
    "getStarted": "https://orc.apache.org/docs/pyarrow.html",
    "EITMLI18": "ORC is like a highly organized, space-saving container for your data, particularly good for storing and processing large amounts of data in Hadoop ecosystems.",
    "url": "https://orc.apache.org",
    "useCases": "- Columnar storage\n- Big data analytics\n- Data warehousing",
    "isOpenSource": true
  },
  {
    "pageUrl": "snowflake",
    "name": "Snowflake",
    "category": "Data Warehouse",
    "description": "Snowflake is a cloud-based data warehousing platform that separates compute and storage for scalability and cost-effectiveness.",
    "logo": "https://cdn.icon-icons.com/icons2/2699/PNG/512/snowflake_logo_icon_167979.png",
    "getStarted": "https://quickstarts.snowflake.com/",
    "EITMLI18": "Snowflake is a cloud-based data warehouse that allows you to store and analyze large amounts of structured and semi-structured data, with the ability to scale computing resources independently of storage.",
    "url": "https://www.snowflake.com",
    "useCases": "- Data warehousing\n- Big data analytics\n- Cloud data platform",
    "isOpenSource": false
  },
  {
    "pageUrl": "hive",
    "name": "Apache Hive",
    "category": "Data Warehouse",
    "description": "Apache Hive is a data warehouse software project built on top of Apache Hadoop, providing a SQL-like interface.",
    "logo": "https://cdn.icon-icons.com/icons2/2699/PNG/512/apache_hive_logo_icon_167867.png",
    "getStarted": "https://cwiki.apache.org/confluence/display/Hive/GettingStarted",
    "EITMLI18": "Hive provides a SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop, making it easier to apply structure to large datasets.",
    "url": "https://hive.apache.org",
    "useCases": "- Big data querying\n- Data warehousing\n- ETL processing",
    "isOpenSource": true
  },
  {
    "pageUrl": "bigquery",
    "name": "Google BigQuery",
    "category": "Data Warehouse",
    "description": "BigQuery is a fully-managed, serverless data warehouse that enables super-fast SQL queries using the processing power of Google's infrastructure.",
    "logo": "https://www.vectorlogo.zone/logos/google_bigquery/google_bigquery-icon.svg",
    "getStarted": "https://cloud.google.com/bigquery/docs/quickstarts/query-public-dataset-console",
    "EITMLI18": "BigQuery is a powerful data warehouse that allows you to run SQL queries on massive datasets quickly, without needing to manage any infrastructure.",
    "url": "https://cloud.google.com/bigquery",
    "useCases": "- Data warehousing\n- Big data analytics\n- Real-time analysis",
    "isOpenSource": false
  },
  {
    "pageUrl": "redshift",
    "name": "AWS Redshift",
    "category": "Data Warehouse",
    "description": "Amazon Redshift is a fully managed, petabyte-scale data warehouse service in the cloud.",
    "logo": "https://icon.icepanel.io/AWS/svg/Analytics/Redshift.svg",
    "getStarted": "https://docs.aws.amazon.com/redshift/latest/gsg/new-user-serverless.html",
    "EITMLI18": "Redshift is a cloud-based data warehouse that allows you to analyze large volumes of data using your existing business intelligence tools, with fast query performance.",
    "url": "https://aws.amazon.com/redshift",
    "useCases": "- Data warehousing\n- Business intelligence\n- Big data analytics",
    "isOpenSource": true
  },
  {
    "pageUrl": "druid",
    "name": "Apache Druid",
    "category": "Database",
    "description": "Apache Druid is a high-performance, real-time analytics database designed for fast slice-and-dice analytics on large data sets.",
    "logo": "https://open-metadata.org/_ipx/w_2048,q_75/%2Fassets%2Fservices%2Fdruid.webp?url=%2Fassets%2Fservices%2Fdruid.webp&w=2048&q=75",
    "getStarted": "https://druid.apache.org/docs/latest/tutorials/",
    "EITMLI18": "Druid is a real-time analytics database that allows you to run fast, interactive queries on large datasets, especially useful for powering user-facing analytic applications.",
    "url": "https://druid.apache.org",
    "useCases": "- Real-time analytics\n- Time series data\n- OLAP",
    "isOpenSource": true
  },
  {
    "pageUrl": "postgresql",
    "name": "PostgreSQL",
    "category": "Database",
    "description": "PostgreSQL is a powerful, open-source object-relational database system. It's known for reliability, feature robustness, and performance.",
    "logo": "https://www.postgresql.org/media/img/about/press/elephant.png",
    "getStarted": "https://www.postgresqltutorial.com/",
    "EITMLI18": "PostgreSQL is a sophisticated database system that allows you to store, retrieve, and manage complex data structures efficiently, with support for advanced queries and transactions.",
    "url": "https://www.postgresql.org",
    "useCases": "- Relational database\n- ACID-compliant transactions\n- Complex queries",
    "isOpenSource": true
  },
  {
    "pageUrl": "cassandra",
    "name": "Apache Cassandra",
    "category": "Database",
    "description": "Apache Cassandra is a highly scalable, high-performance distributed NoSQL database.",
    "logo": "https://cdn.icon-icons.com/icons2/2699/PNG/512/apache_cassandra_logo_icon_170572.png",
    "getStarted": "https://cassandra.apache.org/doc/latest/cassandra/getting_started/index.html",
    "EITMLI18": "Cassandra is a NoSQL database designed to handle large amounts of structured data across many commodity servers, providing high availability with no single point of failure.",
    "url": "https://cassandra.apache.org",
    "useCases": "- NoSQL database\n- High availability\n- Scalable data storage",
    "isOpenSource": false
  },
  {
    "pageUrl": "duckdb",
    "name": "DuckDB",
    "category": "Database",
    "description": "DuckDB is an in-process SQL OLAP database management system, designed to be fast and easy to use for analytical queries.",
    "logo": "https://pbs.twimg.com/profile_images/1274363897676521474/qgbqYYuV_400x400.jpg",
    "getStarted": "https://duckdb.org/docs/api/python/overview.html",
    "EITMLI18": "DuckDB is a lightweight, fast SQL database that runs within your application process, making it ideal for quick data analysis and processing without the need for a separate database server.",
    "url": "https://duckdb.org",
    "useCases": "- In-process analytics\n- Data science\n- Embedded databases",
    "isOpenSource": true
  },
  {
    "pageUrl": "sqllite",
    "name": "SQLite",
    "category": "Database",
    "description": "SQLite is a C-language library that implements a small, fast, self-contained, high-reliability, full-featured, SQL database engine.",
    "logo": "https://anturis.com/wp-content/uploads/2022/09/SQLite-Logo-1.png",
    "getStarted": "https://www.sqlite.org/quickstart.html",
    "EITMLI18": "SQLite is like a mini database that lives right inside your application, perfect for when you need a reliable way to store and retrieve data without setting up a separate database server.",
    "url": "https://www.sqlite.org",
    "useCases": "- Embedded databases\n- Local data storage\n- Application file format",
    "isOpenSource": true
  },
  {
    "pageUrl": "supabase",
    "name": "Supabase",
    "category": "Database;Storage;Query Engine",
    "description": "Supabase is an open-source Firebase alternative providing all the backend features developers need to build a product: a Postgres database, Authentication, instant APIs, Edge Functions, Realtime subscriptions, and Storage.",
    "logo": "https://seeklogo.com/images/S/supabase-logo-DCC676FFE2-seeklogo.com.png",
    "getStarted": "https://supabase.com/docs/guides/getting-started",
    "EITMLI18": "Supabase is like a fully-equipped workshop for app developers, giving you all the tools you need to build the backend of your app quickly - database, user login, APIs, and more, all in one place.",
    "url": "https://supabase.com",
    "useCases": "- Backend-as-a-Service\n- Real-time databases\n- Authentication",
    "isOpenSource": true
  },
  {
    "pageUrl": "clickhouse",
    "name": "ClickHouse",
    "category": "Database; Data Warehouse",
    "description": "ClickHouse is an open-source column-oriented database management system for online analytical processing (OLAP) that allows generating analytical reports using SQL queries in real-time.",
    "logo": "https://asset.brandfetch.io/idnezyZEJm/id_CPPYVKt.jpeg?updated=1684474240695",
    "getStarted": "https://clickhouse.com/docs/en/getting-started/quick-start",
    "EITMLI18": "ClickHouse is a high-performance analytical database that allows you to run complex queries on large datasets very quickly, making it ideal for real-time data analysis and reporting.",
    "url": "https://clickhouse.com",
    "useCases": "- OLAP\n- Real-time analytics\n- Big data processing",
    "isOpenSource": true
  },
  {
    "pageUrl": "terraform",
    "name": "Terraform",
    "category": "Infrastructure as Code",
    "description": "Terraform is an open-source infrastructure as code software tool that enables you to safely and predictably create, change, and improve infrastructure.",
    "logo": "https://cdn.icon-icons.com/icons2/2107/PNG/512/file_type_terraform_icon_130125.png",
    "getStarted": "https://learn.hashicorp.com/terraform",
    "EITMLI18": "Terraform is like a blueprint for your cloud infrastructure, allowing you to define and manage your tech resources using code, making it easier to deploy and maintain complex systems.",
    "url": "https://www.terraform.io",
    "useCases": "- Infrastructure as Code\n- Cloud resource management\n- Multi-cloud deployment",
    "isOpenSource": false
  },
  {
    "pageUrl": "pulumi",
    "name": "Pulumi",
    "category": "Infrastructure as Code",
    "description": "Pulumi is an open-source infrastructure as code tool for creating, deploying, and managing cloud infrastructure using familiar programming languages.",
    "logo": "https://www.pulumi.com/logos/brand/avatar-on-black.svg",
    "getStarted": "https://www.pulumi.com/docs/get-started/",
    "EITMLI18": "Pulumi lets you use programming languages you already know to define and manage your cloud infrastructure, making it easier to create and maintain complex cloud systems.",
    "url": "https://www.pulumi.com",
    "useCases": "- Infrastructure as Code\n- Cloud native development\n- Multi-language support",
    "isOpenSource": true
  },
  {
    "pageUrl": "debezium",
    "name": "Debezium",
    "category": "Ingestion",
    "description": "Debezium is an open source distributed platform for change data capture, built on top of Apache Kafka.",
    "logo": "https://www.vectorlogo.zone/logos/debeziumio/debeziumio-icon.svg",
    "getStarted": "https://debezium.io/documentation/reference/stable/tutorial.html",
    "EITMLI18": "Debezium is like a vigilant observer for your databases, instantly noticing and reporting any changes, which helps keep all your data systems in sync in real-time.",
    "url": "https://debezium.io",
    "useCases": "- Change Data Capture\n- Data integration\n- Real-time data streaming",
    "isOpenSource": true
  },
  {
    "pageUrl": "nifi",
    "name": "Apache NiFi",
    "category": "Ingestion",
    "description": "Apache NiFi is designed to automate the flow of data between systems, supporting powerful and scalable directed graphs of data routing.",
    "logo": "https://nifi.apache.org/images/apache-nifi-drop-logo.svg",
    "getStarted": "https://nifi.apache.org/docs/nifi-docs/html/getting-started.html",
    "EITMLI18": "NiFi provides a web-based interface for designing, controlling, and monitoring a dataflow between systems, allowing you to automate data movement and transformation.",
    "url": "https://nifi.apache.org",
    "useCases": "- Data ingestion\n- Data transformation\n- Data routing",
    "isOpenSource": true
  },
  {
    "pageUrl": "talend",
    "name": "Talend",
    "category": "Ingestion",
    "description": "Talend is a suite of cloud apps for data integration and data integrity, helping companies collect, govern, transform, and share data.",
    "logo": "https://images.crunchbase.com/image/upload/c_pad,h_170,w_170,f_auto,b_white,q_auto:eco,dpr_1/mss7jl4fbxzgvuwbcv6h",
    "getStarted": "https://www.talend.com/knowledge-center/",
    "EITMLI18": "Talend provides a suite of tools for data integration, allowing you to connect, transform, and manage data from various sources in a unified platform.",
    "url": "https://www.talend.com",
    "useCases": "- Data integration\n- ETL processes\n- Data quality management",
    "isOpenSource": false
  },
  {
    "pageUrl": "fivetran",
    "name": "Fivetran",
    "category": "Ingestion",
    "description": "Fivetran is a fully managed data integration platform that helps users replicate data from various sources into data warehouses.",
    "logo": "https://www.vectorlogo.zone/logos/fivetran/fivetran-icon.svg",
    "getStarted": "https://fivetran.com/docs/getting-started",
    "EITMLI18": "Fivetran automates data integration from various sources into your data warehouse, handling the extraction and loading processes so you can focus on analysis.",
    "url": "https://www.fivetran.com",
    "useCases": "- Data integration\n- ETL/ELT\n- Data pipeline automation",
    "isOpenSource": false
  },
  {
    "pageUrl": "stitch",
    "name": "Stitch",
    "category": "Ingestion",
    "description": "Stitch is a cloud-first, open source platform for rapidly moving data.",
    "logo": "https://www.stitchdata.com/images/og-site-icon.png",
    "getStarted": "https://www.stitchdata.com/docs/getting-started/",
    "EITMLI18": "Stitch is a cloud-based platform that helps you quickly and easily replicate data from various sources into your data warehouse for analysis.",
    "url": "https://www.stitchdata.com",
    "useCases": "- Data integration\n- ETL\n- Data pipeline automation",
    "isOpenSource": true
  },
  {
    "pageUrl": "mage",
    "name": "Mage",
    "category": "Ingestion",
    "description": "Mage.ai is an open-source data pipeline tool for transforming and integrating data using Python, SQL, and R.",
    "logo": "https://avatars.githubusercontent.com/u/69371472?s=200&v=4",
    "getStarted": "https://docs.mage.ai/getting-started/setup",
    "EITMLI18": "Mage.ai is a modern data pipeline tool that allows you to build, run, and manage data workflows using familiar languages like Python and SQL, with features like data lineage and scheduling.",
    "url": "https://www.mage.ai",
    "useCases": "- Data orchestration\n- ETL/ELT\n- Data pipeline development",
    "isOpenSource": true
  },
  {
    "pageUrl": "airbyte",
    "name": "Airbyte",
    "category": "Ingestion",
    "description": "Airbyte is an open-source data integration platform that helps you replicate data from applications, APIs, and databases to data warehouses, lakes, and other destinations.",
    "logo": "https://seeklogo.com/images/A/airbyte-logo-CC005A0105-seeklogo.com.png",
    "getStarted": "https://docs.airbyte.com/using-airbyte/getting-started/oss-quickstart",
    "EITMLI18": "Airbyte is a tool that helps you move data from various sources to your preferred destination, with a wide range of pre-built connectors and the ability to build custom ones.",
    "url": "https://airbyte.com",
    "useCases": "- Data integration\n- ETL/ELT\n- Open-source data connectors",
    "isOpenSource": true
  },
  {
    "pageUrl": "meltano",
    "name": "Meltano",
    "category": "Ingestion",
    "description": "Meltano is an open source platform for building, running & orchestrating ELT pipelines.",
    "logo": "https://hub.meltano.com/assets/static/meltano.73f0d34.f6f689a38b0fbf42dc9bfa55e539954a.png",
    "getStarted": "https://docs.meltano.com/getting-started",
    "EITMLI18": "Meltano is an end-to-end DataOps platform that helps you set up and manage the entire data lifecycle, from extraction to transformation to analysis.",
    "url": "https://meltano.com",
    "useCases": "- Data integration\n- ELT\n- DataOps",
    "isOpenSource": true
  },
  {
    "pageUrl": "matillion",
    "name": "Matillion",
    "category": "Ingestion",
    "description": "Matillion Data Loader is a SaaS-based data integration tool that loads data from popular data sources into cloud data platforms.",
    "logo": "https://yt3.googleusercontent.com/3-BKGTk4LOfkdsAZHp8gS-Iyo5L2BkN8uZYgp81CAGzTN8To2wvLfw0ZT2ROUAt2m1kkZNXqlHo=s160-c-k-c0x00ffffff-no-rj",
    "getStarted": "https://www.matillion.com/docs/data-loader-getting-started/",
    "EITMLI18": "Matillion Data Loader is like a efficient conveyor belt, moving your data from various sources into your cloud data warehouse without you needing to write any code.",
    "url": "https://www.matillion.com",
    "useCases": "- Data integration\n- ETL/ELT\n- Cloud data warehousing",
    "isOpenSource": false
  },
  {
    "pageUrl": "rivery",
    "name": "Rivery",
    "category": "Ingestion",
    "description": "Rivery is a SaaS platform for building end-to-end data pipelines, combining ETL, reverse-ETL, and data transformation capabilities.",
    "logo": "https://gdm-catalog-fmapi-prod.imgix.net/ProductLogo/a21ed36a-8964-4ff7-99c6-e7078ed0c34b.png?auto=format%2Ccompress&fit=max&w=96&q=75&ch=Width%2CDPR",
    "getStarted": "https://docs.rivery.io/docs/start-here",
    "EITMLI18": "Rivery is like a Swiss Army knife for data operations, allowing you to collect, transform, and distribute data across your entire data stack with a user-friendly interface.",
    "url": "https://rivery.io",
    "useCases": "- Data integration\n- ETL/ELT\n- Reverse ETL",
    "isOpenSource": false
  },
  {
    "pageUrl": "datuum",
    "name": "Datuum",
    "category": "Ingestion",
    "description": "Datuum is a data quality and observability platform that helps teams monitor, alert, and resolve data quality issues.",
    "logo": "https://datuum.ai/wp-content/themes/datuum/images/datuum-fav.png",
    "getStarted": "https://datuum.ai/#getdemo",
    "EITMLI18": "Datuum is like a quality control inspector for your data, constantly checking for issues and alerting you when something's not right, helping ensure your data is always reliable and trustworthy.",
    "url": "https://datuum.ai",
    "useCases": "- Data quality monitoring\n- Data observability\n- Anomaly detection",
    "isOpenSource": false
  },
  {
    "pageUrl": "informatica",
    "name": "Informatica",
    "category": "Ingestion",
    "description": "Informatica is a comprehensive enterprise data integration and management platform, offering tools for data integration, quality, governance, and master data management.",
    "logo": "https://images.contentstack.io/v3/assets/bltf2fca5bf44f5e817/blt56ff4c76be4b6769/654292efa7f5f10018700465/informatica-logo.png",
    "getStarted": "https://www.informatica.com/products/cloud-data-integration.html",
    "EITMLI18": "Informatica is like a Swiss Army knife for enterprise data management, providing a wide range of tools to help large organizations collect, organize, clean, and use their data effectively across different systems and departments.",
    "url": "https://www.informatica.com",
    "useCases": "- Data integration\n- Data quality\n- Master data management",
    "isOpenSource": false
  },
  {
    "pageUrl": "dlt",
    "name": "Data Load Tool (DLT)",
    "category": "Ingestion",
    "description": "dlthub is a modern data engineering platform that simplifies the process of building and managing data pipelines, with a focus on dbt integration and data quality.",
    "logo": "https://cdn.sanity.io/images/nsq559ov/production/7f85e56e715b847c5519848b7198db73f793448d-82x25.svg?w=2000&auto=format",
    "getStarted": "https://dlthub.com/docs/tutorial/intro",
    "EITMLI18": "dlthub is like a smart assistant for data engineers, helping you build, test, and deploy data pipelines more easily, with built-in support for dbt and tools to ensure your data is reliable and up-to-date.",
    "url": "https://dlthub.com",
    "useCases": "- Data integration\n- ETL pipelines\n- Data quality",
    "isOpenSource": true
  },
  {
    "pageUrl": "portable",
    "name": "Portable",
    "category": "Ingestion",
    "description": "Portable is a modern ELT platform that offers hundreds of pre-built connectors to sync data from various sources to data warehouses and data lakes.",
    "logo": "https://images.crunchbase.com/image/upload/c_pad,h_170,w_170,f_auto,b_white,q_auto:eco,dpr_1/shppofmvueo4mzwu9ehc",
    "getStarted": "https://portable.io/learn",
    "EITMLI18": "Portable is like a universal adapter for your data, allowing you to easily connect and sync information from many different apps and databases into your central data storage, without needing to write complex code for each connection.",
    "url": "https://portable.io",
    "useCases": "- Data integration\n- ETL\n- No-code connectors",
    "isOpenSource": false
  },
  {
    "pageUrl": "streamkap",
    "name": "Streamkap",
    "category": "Ingestion;Transformation",
    "description": "Streamkap is a real-time data integration platform that enables continuous data replication and transformation (via apache Kafka and Flink) across databases, data warehouses, and data lakes.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/streamkap.png",
    "getStarted": "https://docs.streamkap.com/docs/getting-started",
    "EITMLI18": "Streamkap is a platform that allows you to move and transform data in real-time between different systems, enabling you to keep your data synchronized across various databases and analytics platforms.",
    "url": "https://streamkap.com",
    "useCases": "- Real-time data integration\n- Data replication\n- Streaming ETL",
    "isOpenSource": false
  },
  {
    "pageUrl": "datacoves",
    "name": "Datacoves",
    "category": "Ingestion;Transformation",
    "description": "Datacoves is a modern data development environment that integrates with dbt, Airflow, and other tools to streamline the entire data lifecycle.",
    "logo": "https://pbs.twimg.com/profile_images/1662116534322438144/sG4Fphrx_400x400.png",
    "getStarted": "https://github.com/datacoves/dbt-coves?tab=readme-ov-file#installation",
    "EITMLI18": "Datacoves is a platform that brings together various data tools and best practices, helping you manage your entire data workflow from development to deployment more efficiently.",
    "url": "https://datacoves.com",
    "useCases": "- Data development environment\n- DataOps\n- Collaboration",
    "isOpenSource": false
  },
  {
    "pageUrl": "java",
    "name": "Java",
    "category": "Language",
    "description": "Java is a versatile, object-oriented programming language used for developing a wide range of applications, from web to enterprise software.",
    "logo": "https://cdn.icon-icons.com/icons2/2415/PNG/512/java_original_logo_icon_146458.png",
    "getStarted": "https://dev.java/learn/getting-started/",
    "EITMLI18": "Java is a powerful, general-purpose programming language that allows you to write code once and run it on any platform, making it ideal for building large-scale, robust applications.",
    "url": "https://www.java.com",
    "useCases": "- Enterprise software development\n- Android app development\n- Web application backend",
    "isOpenSource": true
  },
  {
    "pageUrl": "sql",
    "name": "SQL",
    "category": "Language",
    "description": "SQL (Structured Query Language) is a standard language for storing, manipulating and retrieving data in relational databases.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/sql.png",
    "getStarted": "https://www.w3schools.com/sql/sql_intro.asp",
    "EITMLI18": "SQL is the primary language used to interact with relational databases, allowing you to create, read, update, and delete data, as well as perform complex queries and data analysis.",
    "url": "https://aws.amazon.com/what-is/sql/",
    "useCases": "- Database querying\n- Data manipulation\n- Data analysis",
    "isOpenSource": true
  },
  {
    "pageUrl": "python",
    "name": "Python",
    "category": "Language",
    "description": "Python is a high-level, interpreted programming language known for its simplicity and readability. It supports multiple programming paradigms and has a large standard library.",
    "logo": "https://cdn.icon-icons.com/icons2/2699/PNG/512/python_logo_icon_168886.png",
    "getStarted": "https://docs.python.org/3/tutorial/",
    "EITMLI18": "Python is like a Swiss Army knife for programming - it's versatile, easy to learn, and can be used for almost anything from web development and data analysis to artificial intelligence.",
    "url": "https://www.python.org",
    "useCases": "- Software Development\n- Data analysis\n- Machine learning",
    "isOpenSource": true
  },
  {
    "pageUrl": "sqlalchemy",
    "name": "SQLAlchemy",
    "category": "Library",
    "description": "SQLAlchemy is a comprehensive set of tools for working with databases in Python, including an ORM and a core SQL abstraction layer.",
    "logo": "https://icon.icepanel.io/Technology/png-shadow-512/SQLAlchemy.png",
    "getStarted": "https://docs.sqlalchemy.org/en/14/intro.html",
    "EITMLI18": "SQLAlchemy is a Python library that allows you to interact with databases using Python code instead of raw SQL, making it easier to work with databases in your applications.",
    "url": "https://www.sqlalchemy.org",
    "useCases": "- ORM\n- Database abstraction\n- SQL generation",
    "isOpenSource": true
  },
  {
    "pageUrl": "polars",
    "name": "Polars",
    "category": "Library;Transformation; Query Engine",
    "description": "Polars is a fast multi-threaded DataFrame library implemented in Rust, with a Python front-end.",
    "logo": "https://pola.rs/favicon.svg",
    "getStarted": "https://docs.pola.rs/user-guide/getting-started/",
    "EITMLI18": "Polars is a high-performance data manipulation library that allows you to process large datasets quickly using multiple CPU cores, with an intuitive API similar to Pandas but with better performance for large datasets.",
    "url": "https://www.pola.rs",
    "useCases": "- High-performance data manipulation\n- Data analysis\n- Large dataset processing",
    "isOpenSource": true
  },
  {
    "pageUrl": "pandas",
    "name": "Pandas",
    "category": "Library;Transformation;Query Engine",
    "description": "Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of Python.",
    "logo": "https://pandas.pydata.org/static/img/pandas_mark_white.svg",
    "getStarted": "https://pandas.pydata.org/docs/getting_started/index.html",
    "EITMLI18": "Pandas is a Python library that provides high-performance, easy-to-use data structures and data analysis tools, allowing you to manipulate and analyze structured data efficiently.",
    "url": "https://pandas.pydata.org",
    "useCases": "- Data manipulation\n- Data analysis\n- Time series analysis",
    "isOpenSource": true
  },
  {
    "pageUrl": "dms",
    "name": "Amazon DMS",
    "category": "Migration",
    "description": "Amazon Database Migration Service (DMS) helps you migrate databases to AWS quickly and securely.",
    "logo": "https://icon.icepanel.io/AWS/svg/Database/Database-Migration-Service.svg",
    "getStarted": "https://docs.aws.amazon.com/dms/latest/userguide/CHAP_GettingStarted.SettingUp.html",
    "EITMLI18": "Amazon DMS is like a moving company for your data, helping you transfer your databases to the AWS cloud quickly and safely, with minimal downtime.",
    "url": "https://aws.amazon.com/dms",
    "useCases": "- Database migration\n- Data replication\n- Schema conversion",
    "isOpenSource": false
  },
  {
    "pageUrl": "metaplane",
    "name": "Metaplane",
    "category": "Observability",
    "description": "Metaplane is a data observability platform that helps data teams monitor the health and quality of their data pipelines, detect anomalies, and prevent data issues.",
    "logo": "https://asset.brandfetch.io/idZRN0Azs7/idVNPufMVy.svg?updated=1684835443623",
    "getStarted": "https://docs.metaplane.dev/docs/getting-started",
    "EITMLI18": "Metaplane is like a health monitor for your data systems, constantly checking vital signs, alerting you to anomalies, and helping you diagnose and fix issues before they cause problems for your business.",
    "url": "https://www.metaplane.dev",
    "useCases": "- Data observability\n- Data quality monitoring\n- Anomaly detection",
    "isOpenSource": false
  },
  {
    "pageUrl": "airflow",
    "name": "Apache Airflow",
    "category": "Orchestration",
    "description": "Apache Airflow is a platform to programmatically author, schedule, and monitor workflows. It uses DAGs for workflow orchestration.",
    "logo": "https://cwiki.apache.org/confluence/download/attachments/145723561/airflow_transparent.png?api=v2",
    "getStarted": "https://airflow.apache.org/docs/apache-airflow/stable/start.html",
    "EITMLI18": "Airflow is a platform for programming complex computational workflows, allowing you to schedule and monitor data pipelines using Python code.",
    "url": "https://airflow.apache.org",
    "useCases": "- Workflow orchestration\n- ETL pipelines\n- Task scheduling",
    "isOpenSource": true
  },
  {
    "pageUrl": "luigi",
    "name": "Luigi",
    "category": "Orchestration",
    "description": "Luigi is a Python package that helps you build complex pipelines of batch jobs, handling dependency resolution and workflow management.",
    "logo": "https://raw.githubusercontent.com/spotify/luigi/master/doc/luigi.png",
    "getStarted": "https://luigi.readthedocs.io/en/stable/",
    "EITMLI18": "Luigi is a Python library that helps you manage complex data processing pipelines, handling task scheduling, dependency resolution, and workflow management.",
    "url": "https://luigi.readthedocs.io/en/stable/index.html",
    "useCases": "- Data pipeline management\n- Batch job scheduling\n- Dependency resolution",
    "isOpenSource": true
  },
  {
    "pageUrl": "dagster",
    "name": "Dagster",
    "category": "Orchestration",
    "description": "Dagster is a data orchestrator for machine learning, analytics, and ETL.",
    "logo": "https://dagster.io/images/brand/logos/dagster-reversed-mark.svg",
    "getStarted": "https://docs.dagster.io/tutorial",
    "EITMLI18": "Dagster is a data orchestration tool that allows you to define, manage, and monitor data pipelines using Python code, with built-in testing and error handling capabilities.",
    "url": "https://dagster.io",
    "useCases": "- Data orchestration\n- ETL pipelines\n- Data quality",
    "isOpenSource": true
  },
  {
    "pageUrl": "prefect",
    "name": "Prefect",
    "category": "Orchestration",
    "description": "Prefect is a workflow management system designed for modern data infrastructure.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/prefect.png",
    "getStarted": "https://docs-3.prefect.io/3.0rc/get-started/quickstart",
    "EITMLI18": "Prefect allows you to build, run, and monitor complex data workflows, with features like automatic retries, dynamic workflows, and real-time monitoring.",
    "url": "https://www.prefect.io",
    "useCases": "- Workflow orchestration\n- Data pipeline management\n- Task scheduling",
    "isOpenSource": true
  },
  {
    "pageUrl": "orchestra",
    "name": "Orchestra",
    "category": "Orchestration",
    "description": "Orchestra is an open-source platform for orchestrating data pipelines and machine learning workflows.",
    "logo": "https://cdn.prod.website-files.com/6541750d4db1a741ed66738c/66934478274bbd9e85cb9b94_Data%20Orchestration%20Icon.png",
    "getStarted": "https://orchestra-1.gitbook.io/orchestra-portal/quick-start",
    "EITMLI18": "Orchestra helps you manage complex data and ML tasks by coordinating different steps and ensuring they run in the right order, like a conductor leading an orchestra.",
    "url": "https://www.getorchestra.io/",
    "useCases": "- ML workflow orchestration\n- Data pipeline management\n- Model deployment",
    "isOpenSource": true
  },
  {
    "pageUrl": "astronomer",
    "name": "Astronomer",
    "category": "Orchestration",
    "description": "Astronomer is a data orchestration platform powered by Apache Airflow, offering tools to develop, orchestrate, and monitor data pipelines.",
    "logo": "https://www.astronomer.io/favicon.svg",
    "getStarted": "https://www.astronomer.io/docs/astro/cli/overview",
    "EITMLI18": "Astronomer is like a mission control center for your data workflows, helping you design, schedule, and monitor complex data processes using the power of Apache Airflow, but with added tools and support.",
    "url": "https://www.astronomer.io",
    "useCases": "- Airflow management\n- Data pipeline orchestration\n- ETL workflows",
    "isOpenSource": false
  },
  {
    "pageUrl": "kestra",
    "name": "Kestra",
    "category": "Orchestration",
    "description": "Kestra is an open-source, event-driven, and schedule-based workflow orchestration platform that helps you build, run, schedule, and monitor complex data pipelines.",
    "logo": "https://kestra.io/favicon-192x192.png",
    "getStarted": "https://kestra.io/docs/tutorial",
    "EITMLI18": "Kestra is like a skilled conductor for your data orchestra, coordinating various data tasks and processes to work together seamlessly, whether they need to run on a schedule or in response to specific events.",
    "url": "https://kestra.io",
    "useCases": "- Workflow orchestration\n- Data pipeline management\n- Event-driven workflows",
    "isOpenSource": true
  },
  {
    "pageUrl": "y42",
    "name": "Y42",
    "category": "Orchestration; Ingestion",
    "description": "Y42 is a modern, self-service data platform that integrates data integration, transformation, orchestration, and analytics in one tool.",
    "logo": "https://media.graphassets.com/output=format:jpg/resize=,width:59,height:59,fit:crop/pFV2MSfWQGAN6ruQEc6s",
    "getStarted": "https://www.y42.com/docs/getting-started",
    "EITMLI18": "Y42 is like a one-stop-shop for data work, allowing you to pull in data from various sources, clean it up, run analyses, and create visualizations all in one place, without needing to switch between different tools.",
    "url": "https://www.y42.com",
    "useCases": "- Data integration\n- Data transformation\n- Data visualization",
    "isOpenSource": false
  },
  {
    "pageUrl": "fabric",
    "name": "Microsoft Fabric",
    "category": "Orchestration; Ingestion",
    "description": "Microsoft Fabric is an all-in-one analytics solution for enterprises, unifying various data and analytics tools into a single, integrated platform.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/fabric.png",
    "getStarted": "https://learn.microsoft.com/en-us/fabric/get-started/end-to-end-tutorials",
    "EITMLI18": "Microsoft Fabric is like a complete toolbox for working with data in large organizations, bringing together tools for data storage, processing, analysis, and visualization in one place, making it easier to manage and use data across the entire company.",
    "url": "https://www.microsoft.com/en-us/microsoft-fabric",
    "useCases": "- Data integration\n- Analytics\n- Data visualization",
    "isOpenSource": false
  },
  {
    "pageUrl": "data-factory",
    "name": "Azure Data Factory",
    "category": "Orchestration;Ingestion",
    "description": "Azure Data Factory is a cloud-based ETL and data integration service that allows you to create data-driven workflows for orchestrating data movement and transforming data at scale.",
    "logo": "https://code.benco.io/icon-collection/azure-icons/Data-Factory.svg",
    "getStarted": "https://learn.microsoft.com/en-us/azure/data-factory/quickstart-get-started",
    "EITMLI18": "Azure Data Factory is like a data assembly line in the cloud, helping you move and transform data from various sources to where you need it, all managed through a visual interface.",
    "url": "https://azure.microsoft.com/en-us/products/data-factory",
    "useCases": "- Data integration\n- ETL/ELT\n- Data pipeline orchestration",
    "isOpenSource": false
  },
  {
    "pageUrl": "flink",
    "name": "Apache Flink",
    "category": "Processing; Streaming",
    "description": "Apache Flink is a framework and distributed processing engine for stateful computations over data streams.",
    "logo": "https://cdn.icon-icons.com/icons2/2699/PNG/512/apache_flink_logo_icon_168620.png",
    "getStarted": "https://ci.apache.org/projects/flink/flink-docs-release-1.14/docs/try-flink/datastream/",
    "EITMLI18": "Flink is a powerful stream processing framework that allows you to process and analyze real-time data streams with high throughput and low latency.",
    "url": "https://flink.apache.org",
    "useCases": "- Stream processing\n- Real-time analytics\n- Event-driven applications",
    "isOpenSource": true
  },
  {
    "pageUrl": "stream-analytics",
    "name": "Azure Stream Analytics",
    "category": "Processing; Streaming",
    "description": "Azure Stream Analytics is a real-time analytics and complex event-processing engine that is designed to analyze and process high volumes of fast streaming data from multiple sources simultaneously.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/stream_analytics.png",
    "getStarted": "https://learn.microsoft.com/en-us/azure/stream-analytics/quick-start-build-application",
    "EITMLI18": "Azure Stream Analytics is like a super-fast data analyst that can process and analyze data as it's coming in, helping you get insights from your data in real-time.",
    "url": "https://azure.microsoft.com/en-us/products/stream-analytics",
    "useCases": "- Real-time analytics\n- IoT data processing\n- Anomaly detection",
    "isOpenSource": false
  },
  {
    "pageUrl": "hudi",
    "name": "Apache Hudi",
    "category": "Processing;Streaming",
    "description": "Apache Hudi (Hadoop Upserts Deletes and Incrementals) is a data management framework for faster processing and incremental updates to big data.",
    "logo": "https://hudi.apache.org/assets/images/logo-big.png",
    "getStarted": "https://hudi.apache.org/docs/quick-start-guide",
    "EITMLI18": "Hudi is a data management framework that allows you to perform upserts, deletes, and incremental data processing on large datasets stored in data lakes.",
    "url": "https://hudi.apache.org",
    "useCases": "- Data lake management\n- Incremental processing\n- ACID transactions on data lakes",
    "isOpenSource": true
  },
  {
    "pageUrl": "beam",
    "name": "Apache Beam",
    "category": "Processing;Streaming",
    "description": "Apache Beam provides a unified programming model for defining and executing data processing pipelines.",
    "logo": "https://cdn.icon-icons.com/icons2/2699/PNG/512/apache_beam_logo_icon_168624.png",
    "getStarted": "https://beam.apache.org/get-started/quickstart-py/",
    "EITMLI18": "Beam offers a unified programming model to define and execute data processing pipelines, including batch and streaming data processing jobs that can run on various execution engines.",
    "url": "https://beam.apache.org",
    "useCases": "- Data processing\n- ETL pipelines\n- Unified batch and stream processing",
    "isOpenSource": true
  },
  {
    "pageUrl": "databricks",
    "name": "Databricks",
    "category": "Processing;Streaming;Query Engine",
    "description": "Databricks provides a unified analytics platform built on top of Apache Spark, designed for data science and engineering teams.",
    "logo": "https://asset.brandfetch.io/idSUrLOWbH/idQeSz8UHv.svg?updated=1668081624532",
    "getStarted": "https://www.databricks.com/learn",
    "EITMLI18": "Databricks offers a collaborative platform for data science and engineering, allowing you to easily process large amounts of data, build machine learning models, and create data pipelines.",
    "url": "https://www.databricks.com",
    "useCases": "- Big data processing\n- Machine learning\n- Data engineering",
    "isOpenSource": false
  },
  {
    "pageUrl": "spark",
    "name": "Apache Spark",
    "category": "Processing;Streaming;Query Engine",
    "description": "Apache Spark is a unified analytics engine for large-scale data processing. It supports batch processing, real-time streaming, machine learning, and graph processing.",
    "logo": "https://cdn.icon-icons.com/icons2/2699/PNG/512/apache_spark_logo_icon_170560.png",
    "getStarted": "https://spark.apache.org/docs/latest/quick-start.html",
    "EITMLI18": "Spark is like a high-performance engine for data processing, allowing you to analyze massive datasets quickly using distributed computing techniques.",
    "url": "https://spark.apache.org",
    "useCases": "- Big data processing\n- Machine learning\n- Stream processing",
    "isOpenSource": true
  },
  {
    "pageUrl": "great-expectations",
    "name": "Great Expectations",
    "category": "Quality",
    "description": "Great Expectations is a Python-based open-source library for validating, documenting, and profiling data.",
    "logo": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSjkqYHr049iwVfZYm67YaebpFhPsWogNpUoypOkgbuVblVB9BJ-T6L5NhHjrsrrwsc3NA&usqp=CAU",
    "getStarted": "https://docs.greatexpectations.io/docs/reference/learn/data_quality_use_cases/dq_use_cases_lp",
    "EITMLI18": "Great Expectations is like a quality control system for your data, helping you catch and prevent data quality issues before they cause problems in your analysis or applications.",
    "url": "https://greatexpectations.io",
    "useCases": "- Data validation\n- Data quality\n- Data testing",
    "isOpenSource": true
  },
  {
    "pageUrl": "pydantic",
    "name": "Pydantic",
    "category": "Quality",
    "description": "Pydantic is a data validation and settings management library using Python type annotations, ensuring your data's integrity and structure.",
    "logo": "https://avatars.githubusercontent.com/u/110818415?v=4",
    "getStarted": "https://pydantic-docs.helpmanual.io/usage/models/",
    "EITMLI18": "Pydantic helps you define what shape your data should have and automatically validates it, catching errors early and making your code more reliable and easier to understand.",
    "url": "https://pydantic-docs.helpmanual.io",
    "useCases": "- Data validation\n- Settings management\n- Serialization",
    "isOpenSource": true
  },
  {
    "pageUrl": "starburst",
    "name": "Starburst",
    "category": "Query Engine",
    "description": "Starburst is a fast and flexible query engine built on open source Trino, designed to query data across any database.",
    "logo": "https://images.crunchbase.com/image/upload/c_pad,h_170,w_170,f_auto,b_white,q_auto:eco,dpr_1/imsmiqjafibkwqzcwsrb",
    "getStarted": "https://docs.starburst.io/introduction/index.html",
    "EITMLI18": "Starburst is like a universal translator for databases, allowing you to query data across multiple sources as if they were all in one place, making it easier to analyze data spread across different systems.",
    "url": "https://www.starburst.io",
    "useCases": "- Distributed SQL querying\n- Data federation\n- Data lake analytics",
    "isOpenSource": false
  },
  {
    "pageUrl": "athena",
    "name": "AWS Athena",
    "category": "Query Engine",
    "description": "Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL.",
    "logo": "https://icon.icepanel.io/AWS/svg/Analytics/Athena.svg",
    "getStarted": "https://docs.aws.amazon.com/athena/latest/ug/getting-started.html",
    "EITMLI18": "Athena is like having a powerful SQL engine that can directly query your data stored in S3, without needing to set up and manage any servers.",
    "url": "https://aws.amazon.com/athena",
    "useCases": "- Serverless querying\n- Data lake analytics\n- Ad-hoc analysis",
    "isOpenSource": false
  },
  {
    "pageUrl": "trino",
    "name": "Trino",
    "category": "Query Engine",
    "description": "Trino (formerly PrestoSQL) is an open-source distributed SQL query engine designed to query large data sets distributed over one or more heterogeneous data sources.",
    "logo": "https://avatars.githubusercontent.com/u/34147222?s=200&v=4",
    "getStarted": "https://trino.io/docs/current/installation/deployment.html",
    "EITMLI18": "Trino is like a super-fast librarian that can find and combine information from many different libraries at once, allowing you to ask complex questions about data stored in various places and get quick answers.",
    "url": "https://trino.io",
    "useCases": "- Distributed SQL querying\n- Big data analytics\n- Data federation",
    "isOpenSource": true
  },
  {
    "pageUrl": "dremio",
    "name": "Dremio",
    "category": "Query Engine",
    "description": "Dremio is an open-source data lake engine that provides fast query capabilities over data lakes, along with data virtualization and data acceleration technologies.",
    "logo": "https://www.vectorlogo.zone/logos/dremio/dremio-icon.svg",
    "getStarted": "https://docs.dremio.com/current/get-started/",
    "EITMLI18": "Dremio is like a high-speed train for your data lake, allowing you to quickly access and analyze data stored in various formats and locations without needing to move or copy it, making it easier to get insights from large amounts of diverse data.",
    "url": "https://www.dremio.com",
    "useCases": "- Data lake engine\n- SQL acceleration\n- Data virtualization",
    "isOpenSource": true
  },
  {
    "pageUrl": "elasticsearch",
    "name": "Elasticsearch",
    "category": "Query Engine",
    "description": "Elasticsearch is a distributed, RESTful search and analytics engine capable of solving various use cases.",
    "logo": "https://cdn.worldvectorlogo.com/logos/elasticsearch.svg",
    "getStarted": "https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html",
    "EITMLI18": "Elasticsearch is a powerful search and analytics engine that allows you to store, search, and analyze large volumes of data quickly and in near real-time.",
    "url": "https://www.elastic.co",
    "useCases": "- Full-text search\n- Log analytics\n- Application monitoring",
    "isOpenSource": true
  },
  {
    "pageUrl": "s3",
    "name": "AWS S3",
    "category": "Storage",
    "description": "Amazon S3 (Simple Storage Service) is an object storage service offering industry-leading scalability, data availability, security, and performance.",
    "logo": "https://icon.icepanel.io/AWS/svg/Storage/Simple-Storage-Service.svg",
    "getStarted": "https://docs.aws.amazon.com/AmazonS3/latest/userguide/GetStartedWithS3.html",
    "EITMLI18": "S3 is like a giant, reliable storage system in the cloud where you can keep any amount of data, access it quickly, and only pay for what you use.",
    "url": "https://aws.amazon.com/s3",
    "useCases": "- Object storage\n- Data backup\n- Static website hosting",
    "isOpenSource": false
  },
  {
    "pageUrl": "adls-gen2",
    "name": "Microsoft ADLS Gen2",
    "category": "Storage",
    "description": "Azure Data Lake Storage Gen2 is a set of capabilities dedicated to big data analytics, built on Azure Blob storage.",
    "logo": "https://miro.medium.com/v2/resize:fit:600/1*xkem5OSBR4oeQbMptKm6sw.png",
    "getStarted": "https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction",
    "EITMLI18": "ADLS Gen2 is a powerful storage system designed for big data analytics in the cloud, allowing you to store and analyze massive amounts of data efficiently.",
    "url": "https://azure.microsoft.com/en-us/products/storage/data-lake-storage",
    "useCases": "- Data lake storage\n- Big data analytics\n- Hadoop compatible storage",
    "isOpenSource": false
  },
  {
    "pageUrl": "hadoop",
    "name": "Apache Hadoop",
    "category": "Storage;Query Engine",
    "description": "Apache Hadoop is an open-source framework for distributed storage and processing of large datasets using MapReduce.",
    "logo": "https://cdn.icon-icons.com/icons2/2699/PNG/512/apache_hadoop_logo_icon_169586.png",
    "getStarted": "https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html",
    "EITMLI18": "Hadoop is a framework that allows for the distributed processing of large data sets across clusters of computers, using simple programming models like MapReduce.",
    "url": "https://hadoop.apache.org",
    "useCases": "- Distributed storage\n- Big data processing\n- Batch processing",
    "isOpenSource": true
  },
  {
    "pageUrl": "kafka",
    "name": "Apache Kafka",
    "category": "Streaming",
    "description": "Apache Kafka is a distributed event streaming platform used for high-performance data pipelines, streaming analytics, and data integration.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/kafka.png",
    "getStarted": "https://kafka.apache.org/quickstart",
    "EITMLI18": "Kafka is a distributed system for handling real-time data feeds, allowing you to publish, subscribe, store, and process streams of records seamlessly.",
    "url": "https://kafka.apache.org",
    "useCases": "- Event streaming\n- Message queuing\n- Data integration",
    "isOpenSource": true
  },
  {
    "pageUrl": "pulsar",
    "name": "Apache Pulsar",
    "category": "Streaming",
    "description": "Apache Pulsar is a cloud-native, distributed messaging and streaming platform originally created at Yahoo!",
    "logo": "https://vectorseek.com/wp-content/uploads/2023/11/Apache-Pulsar-Icon-Logo-Vector.svg-.png",
    "getStarted": "https://pulsar.apache.org/docs/en/standalone/",
    "EITMLI18": "Pulsar is a distributed messaging system that allows you to build scalable, real-time data streaming applications with support for multiple subscription modes.",
    "url": "https://pulsar.apache.org",
    "useCases": "- Distributed messaging\n- Pub-sub messaging\n- Stream processing",
    "isOpenSource": true
  },
  {
    "pageUrl": "kinesis",
    "name": "AWS Kinesis",
    "category": "Streaming",
    "description": "Amazon Kinesis makes it easy to collect, process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information.",
    "logo": "https://icon.icepanel.io/AWS/svg/Analytics/Kinesis.svg",
    "getStarted": "https://docs.aws.amazon.com/kinesis/latest/dev/getting-started.html",
    "EITMLI18": "Kinesis is like a high-speed conveyor belt for data, allowing you to ingest and process large amounts of streaming data in real-time.",
    "url": "https://aws.amazon.com/kinesis",
    "useCases": "- Real-time streaming\n- Data analytics\n- Application monitoring",
    "isOpenSource": false
  },
  {
    "pageUrl": "redpanda",
    "name": "Redpanda",
    "category": "Streaming",
    "description": "Redpanda is a Kafka-compatible event streaming platform with lower latency, higher throughput, and zero copy architecture.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/redpanda.png",
    "getStarted": "https://docs.redpanda.com/current/get-started/quick-start/",
    "EITMLI18": "Redpanda is like a supercharged version of Kafka, allowing you to process streams of data extremely quickly and efficiently, making it great for real-time data processing.",
    "url": "https://redpanda.com",
    "useCases": "- Kafka-compatible streaming\n- Real-time data processing\n- Event-driven architectures",
    "isOpenSource": true
  },
  {
    "pageUrl": "dbt",
    "name": "dbt",
    "category": "Transformation",
    "description": "dbt is a command-line tool that enables data analysts and engineers to transform data in their warehouses more effectively.",
    "logo": "https://nrphlnibzuquhuzswkqv.supabase.co/storage/v1/object/public/engineeringtools/dbt.png",
    "getStarted": "https://docs.getdbt.com/tutorial/setting-up",
    "EITMLI18": "dbt (data build tool) allows you to transform your data by writing modular SQL select statements, manage model dependencies, and generate documentation for your data warehouse.",
    "url": "https://www.getdbt.com",
    "useCases": "- Data transformation\n- Data modeling\n- Analytics engineering",
    "isOpenSource": true
  },
  {
    "pageUrl": "git",
    "name": "Git",
    "category": "Version Control",
    "description": "Git is a distributed version-control system for tracking changes in source code during software development, designed for coordinating work among programmers.",
    "logo": "https://cdn.icon-icons.com/icons2/2107/PNG/512/file_type_git_icon_130581.png",
    "getStarted": "https://git-scm.com/book/en/v2/Getting-Started-About-Version-Control",
    "EITMLI18": "Git is like a time machine for your code, allowing you to track changes, experiment with new ideas, and collaborate with others without fear of losing your work.",
    "url": "https://git-scm.com",
    "useCases": "- Version control\n- Collaborative development\n- Code management",
    "isOpenSource": true
  },
  {
    "pageUrl": "synapse",
    "name": "Microsoft Synapse",
    "category": "Visualization",
    "description": "Azure Synapse is an analytics service that brings together enterprise data warehousing and Big Data analytics.",
    "logo": "https://azure.microsoft.com/svghandler/synapse-analytics.png",
    "getStarted": "https://learn.microsoft.com/en-us/azure/synapse-analytics/get-started",
    "EITMLI18": "Synapse is an integrated analytics platform that combines data integration, enterprise data warehousing, and big data analytics into a single service.",
    "url": "https://azure.microsoft.com/en-us/products/synapse-analytics",
    "useCases": "- Data warehousing\n- Big data analytics\n- Data integration",
    "isOpenSource": false
  },
  {
    "pageUrl": "looker",
    "name": "Looker",
    "category": "Visualization",
    "description": "Looker is a business intelligence software and big data analytics platform that helps you explore, analyze and share real-time business analytics.",
    "logo": "https://coefficient.io/wp-content/uploads/2022/03/looker.png",
    "getStarted": "https://cloud.google.com/looker/docs/set-up-and-administer-looker",
    "EITMLI18": "Looker is a powerful tool that allows you to create custom data experiences, from simple dashboards to sophisticated data apps, helping you make data-driven decisions.",
    "url": "https://www.looker.com",
    "useCases": "- Business intelligence\n- Data visualization\n- Embedded analytics",
    "isOpenSource": false
  },
  {
    "pageUrl": "powerbi",
    "name": "Power BI",
    "category": "Visualization",
    "description": "Power BI is a business analytics tool by Microsoft for visualizing data and sharing insights across an organization.",
    "logo": "https://1000logos.net/wp-content/uploads/2022/08/Microsoft-Power-BI-Logo.png",
    "getStarted": "https://docs.microsoft.com/en-us/power-bi/fundamentals/desktop-getting-started",
    "EITMLI18": "Power BI is like a powerful magnifying glass for your data, allowing you to create interactive visualizations and dashboards that help you understand and present your data effectively.",
    "url": "https://powerbi.microsoft.com",
    "useCases": "- Data visualization\n- Business intelligence\n- Interactive dashboards",
    "isOpenSource": false
  },
  {
    "pageUrl": "tableau",
    "name": "Tableau",
    "category": "Visualization",
    "description": "Tableau is a visual analytics platform that helps people see and understand data through interactive visualizations.",
    "logo": "https://leadsbridge.com/wp-content/themes/leadsbridge/img/integration-lg-logos/logo1024.png",
    "getStarted": "https://public.tableau.com/en-us/s/resources",
    "EITMLI18": "Tableau is a powerful data visualization tool that allows you to connect to various data sources, create interactive dashboards, and share insights with others easily.",
    "url": "https://www.tableau.com",
    "useCases": "- Data visualization\n- Business intelligence\n- Self-service analytics",
    "isOpenSource": false
  },
  {
    "pageUrl": "superset",
    "name": "Apache Superset",
    "category": "Visualization",
    "description": "Apache Superset is a modern data exploration and visualization platform designed to be visual, intuitive, and interactive.",
    "logo": "https://seeklogo.com/images/S/superset-icon-logo-D70353ADD5-seeklogo.com.png",
    "getStarted": "https://superset.apache.org/docs/quickstart",
    "EITMLI18": "Superset is a data visualization and exploration platform that allows you to create interactive dashboards and perform ad-hoc analyses on your data without writing code.",
    "url": "https://superset.apache.org",
    "useCases": "- Data exploration\n- Data visualization\n- Business intelligence",
    "isOpenSource": true
  },
  {
    "pageUrl": "metabase",
    "name": "Metabase",
    "category": "Visualization",
    "description": "Metabase is an open-source business intelligence tool that lets you create interactive dashboards and ad-hoc queries without SQL.",
    "logo": "https://www.metabase.com/images/logo.svg",
    "getStarted": "https://www.metabase.com/learn/getting-started/getting-started.html",
    "EITMLI18": "Metabase is a user-friendly tool that allows you to explore your data, create visualizations, and share insights with your team, even if you're not a data expert.",
    "url": "https://www.metabase.com",
    "useCases": "- Business intelligence\n- Data visualization\n- Ad-hoc querying",
    "isOpenSource": true
  },
  {
    "pageUrl": "hex",
    "name": "Hex",
    "category": "Visualization",
    "description": "Hex is a collaborative data workspace that combines SQL, Python, and interactive visualizations for data analysis and sharing.",
    "logo": "https://mds-bucket.us-southeast-1.linodeobjects.com/93142832.png",
    "getStarted": "https://learn.hex.tech/tutorials",
    "EITMLI18": "Hex is a platform where you can write code, query databases, create visualizations, and share your work, all in one place, making it easier to collaborate on data projects.",
    "url": "https://hex.tech",
    "useCases": "- Data analysis\n- Collaborative notebooks\n- Data visualization",
    "isOpenSource": false
  }
]